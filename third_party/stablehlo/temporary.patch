diff --ruN a/stablehlo/BUILD.bazel b/stablehlo/BUILD.bazel
--- stablehlo/BUILD.bazel
+++ stablehlo/BUILD.bazel
@@ -21,11 +21,9 @@
 
 exports_files([
     "LICENSE",
-    "stablehlo/integrations/python/ChloModule.cpp",
-    "stablehlo/integrations/python/PortableApi.cpp",
-    "stablehlo/integrations/python/PortableApi.h",
-    "stablehlo/integrations/python/StablehloModule.cpp",
-    "stablehlo/integrations/python/VhloModule.cpp",
+    # Export StablehloApi for MLIR-free portable API users.
+    "stablehlo/integrations/python/StablehloApi.cpp",
+    "stablehlo/integrations/python/StablehloApi.h",
 ])
 
 filegroup(
@@ -251,6 +249,13 @@
         "@llvm-project//mlir:BuiltinDialectTdFiles",
         "@llvm-project//mlir:ControlFlowInterfacesTdFiles",
         "@llvm-project//mlir:OpBaseTdFiles",
+    ],
+)
+
+filegroup(
+    name = "chlo_py_api_files",
+    srcs = [
+        "stablehlo/integrations/python/ChloModule.cpp",
     ],
 )
 
@@ -864,6 +869,7 @@
     "stablehlo/integrations/c/StablehloAttributes.cpp",
     "stablehlo/integrations/c/StablehloDialect.cpp",
     "stablehlo/integrations/c/StablehloPasses.cpp",
+    "stablehlo/integrations/c/StablehloApi.cpp",
     "stablehlo/integrations/c/StablehloTypes.cpp",
 ]
 
@@ -871,6 +877,7 @@
     "stablehlo/integrations/c/StablehloAttributes.h",
     "stablehlo/integrations/c/StablehloDialect.h",
     "stablehlo/integrations/c/StablehloPasses.h",
+    "stablehlo/integrations/c/StablehloApi.h",
     "stablehlo/integrations/c/StablehloTypes.h",
 ]
 
@@ -880,10 +887,17 @@
     hdrs = STABLEHLO_CAPI_HEADERS,
     strip_include_prefix = ".",
     deps = [
+        ":reference_api",
+        ":reference_configuration",
         ":stablehlo_ops",
         ":stablehlo_passes",
+        ":stablehlo_portable_api",
+        ":stablehlo_serialization",
+        ":version",
         "@llvm-project//llvm:Support",
         "@llvm-project//mlir:CAPIIR",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
     ],
 )
 
@@ -904,10 +918,17 @@
     hdrs = STABLEHLO_CAPI_HEADERS,
     strip_include_prefix = ".",
     deps = [
+        ":reference_api",
+        ":reference_configuration",
         ":stablehlo_ops",
         ":stablehlo_passes",
-        "@llvm-project//llvm:Support",
-        "@llvm-project//mlir:CAPIIRObjects",
+        ":stablehlo_portable_api",
+        ":stablehlo_serialization",
+        ":version",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:CAPIIR",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
     ],
     alwayslink = True,
 )
@@ -1002,6 +1023,15 @@
     deps = [
         ":stablehlo_ops_td_files",
         "@llvm-project//mlir:OpBaseTdFiles",
+    ],
+)
+
+filegroup(
+    name = "stablehlo_py_api_files",
+    srcs = [
+        "stablehlo/integrations/python/StablehloApi.cpp",
+        "stablehlo/integrations/python/StablehloApi.h",
+        "stablehlo/integrations/python/StablehloModule.cpp",
     ],
 )
 
@@ -1283,6 +1313,7 @@
         "@llvm-project//mlir:AllExtensions",
         "@llvm-project//mlir:AllPassesAndDialects",
         "@llvm-project//mlir:MlirOptLib",
+        "@llvm-project//mlir:QuantOps",
         "@llvm-project//mlir:TosaDialect",
     ],
 )
diff --ruN a/stablehlo/docs/compatibility.md b/stablehlo/docs/compatibility.md
--- stablehlo/docs/compatibility.md
+++ stablehlo/docs/compatibility.md
@@ -115,9 +115,9 @@
 def get_current_version() -> str: ...
 def get_minimum_version() -> str: ...
 def serialize_portable_artifact(module: ir.Module, target_version: str) -> bytes: ...
-def serialize_portable_artifact(module: str, target_version: str) -> bytes: ...
+def serialize_portable_artifact_str(module: str, target_version: str) -> bytes: ...
 def deserialize_portable_artifact(context: ir.Context, artifact: bytes) -> ir.Module: ...
-def deserialize_portable_artifact(artifact: bytes) -> str: ...
+def deserialize_portable_artifact_str(artifact: bytes) -> str: ...
 ```
 
 See [`StablehloModule.cpp`](https://github.com/openxla/stablehlo/blob/main/stablehlo/integrations/python/StablehloModule.cpp)
diff --ruN a/stablehlo/stablehlo/api/PortableApi.cpp b/stablehlo/stablehlo/api/PortableApi.cpp
--- stablehlo/stablehlo/api/PortableApi.cpp
+++ stablehlo/stablehlo/api/PortableApi.cpp
@@ -38,18 +38,13 @@
 }
 }  // namespace
 
-LogicalResult getSmallerVersion(const std::string& version1,
-                                const std::string& version2,
-                                std::string& result) {
+FailureOr<std::string> getSmallerVersion(llvm::StringRef version1,
+                                         llvm::StringRef version2) {
   auto v1 = mlir::vhlo::Version::fromString(version1);
   auto v2 = mlir::vhlo::Version::fromString(version2);
   if (failed(v1) || failed(v2)) return failure();
-
-  if (*v1 < *v2)
-    result = (*v1).toString();
-  else
-    result = (*v2).toString();
-  return success();
+  if (*v1 < *v2) return (*v1).toString();
+  return (*v2).toString();
 }
 
 std::string getCurrentVersion() {
diff --ruN a/stablehlo/stablehlo/api/PortableApi.h b/stablehlo/stablehlo/api/PortableApi.h
--- stablehlo/stablehlo/api/PortableApi.h
+++ stablehlo/stablehlo/api/PortableApi.h
@@ -27,12 +27,11 @@
 
 /// Return the current version for portable API.
 /// Increments on all meaningful changes to this file.
-inline int64_t getApiVersion() { return 8; }
+inline int64_t getApiVersion() { return 9; }
 
 // Get the smaller version between version1 and version2.
-LogicalResult getSmallerVersion(const std::string& version1,
-                                const std::string& version2,
-                                std::string& result);
+FailureOr<std::string> getSmallerVersion(llvm::StringRef version1,
+                                         llvm::StringRef version2);
 
 // Get the current StableHLO version.
 //
diff --ruN a/stablehlo/stablehlo/conversions/tosa/tests/lit.cfg.py b/stablehlo/stablehlo/conversions/tosa/tests/lit.cfg.py
--- stablehlo/stablehlo/conversions/tosa/tests/lit.cfg.py
+++ stablehlo/stablehlo/conversions/tosa/tests/lit.cfg.py
@@ -32,9 +32,9 @@
 
 # Make LLVM and StableHLO tools available in RUN directives
 tools = [
-  'stablehlo-opt',
-  'FileCheck',
-  'stablehlo-translate',
+    'stablehlo-opt',
+    'FileCheck',
+    'stablehlo-translate',
 ]
 tool_dirs = [
   config.llvm_tools_dir,
diff --ruN a/stablehlo/stablehlo/dialect/Base.cpp b/stablehlo/stablehlo/dialect/Base.cpp
--- stablehlo/stablehlo/dialect/Base.cpp
+++ stablehlo/stablehlo/dialect/Base.cpp
@@ -21,12 +21,15 @@
 #include <cstdint>
 #include <functional>
 #include <optional>
+#include <tuple>
 #include <utility>
 
 #include "llvm/ADT/APInt.h"
+#include "llvm/ADT/Hashing.h"
 #include "llvm/ADT/STLExtras.h"
 #include "llvm/ADT/Sequence.h"
 #include "llvm/ADT/SmallVector.h"
+#include "llvm/Support/Debug.h"
 #include "llvm/Support/ErrorHandling.h"
 #include "mlir/Dialect/Quant/QuantTypes.h"
 #include "mlir/Dialect/Shape/IR/Shape.h"
@@ -42,9 +45,13 @@
 #include "mlir/Interfaces/InferTypeOpInterface.h"
 #include "mlir/Interfaces/SideEffectInterfaces.h"
 #include "mlir/Support/LLVM.h"
+#include "mlir/Support/LogicalResult.h"
+#include "mlir/Support/TypeID.h"
 
 // Include order matters
 #include "stablehlo/dialect/BaseAttrInterfaces.cpp.inc"
+
+#define DEBUG_TYPE "stablehlo-base"
 
 namespace mlir {
 namespace hlo {
@@ -624,6 +631,84 @@
                      [val](int64_t x) { return x == val; });
 }
 
+namespace detail {
+template <typename LHS, typename RHS, typename Accum, int64_t N>
+bool match(Type lhsPrecisionType, Type rhsPrecisionType, Type accumulationType,
+           int64_t numPrimitiveOperations) {
+  return isa<LHS>(lhsPrecisionType) && isa<RHS>(rhsPrecisionType) &&
+         isa<Accum>(accumulationType) && numPrimitiveOperations == N;
+}
+
+FailureOr<KnownDotAlgorithm> getKnownDotAlgorithm(
+    Type lhsPrecisionType, Type rhsPrecisionType, Type accumulationType,
+    int64_t lhsComponentCount, int64_t rhsComponentCount,
+    int64_t numPrimitiveOperations, bool allowImpreciseAccumulation) {
+  // Only support single component for now.
+  if (lhsComponentCount != 1 || rhsComponentCount != 1) return failure();
+
+  auto isAnyF8 = [](Type t) {
+    return llvm::isa<Float8E4M3FNType, Float8E5M2Type, Float8E4M3FNUZType,
+                     Float8E4M3B11FNUZType, Float8E5M2FNUZType>(t);
+  };
+  if (isAnyF8(lhsPrecisionType) && isAnyF8(rhsPrecisionType) &&
+      accumulationType.isF32() && numPrimitiveOperations == 1) {
+    if (allowImpreciseAccumulation)
+      return KnownDotAlgorithm::ANY_F8_ANY_F8_F32_FAST_ACCUM;
+    return KnownDotAlgorithm::ANY_F8_ANY_F8_F32;
+  }
+  if (allowImpreciseAccumulation) return failure();
+
+  // TypeID doesn't define a `<` operator so cannot use in map.
+  // Use its name instead.
+  auto key = std::make_tuple(lhsPrecisionType.getAbstractType().getName(),
+                             rhsPrecisionType.getAbstractType().getName(),
+                             accumulationType.getAbstractType().getName(),
+                             numPrimitiveOperations);
+
+  StringRef bf16 = BFloat16Type::name;
+  StringRef f16 = Float16Type::name;
+  StringRef f32 = Float32Type::name;
+  StringRef f64 = Float64Type::name;
+  StringRef tf32 = FloatTF32Type::name;
+  std::map<std::tuple<StringRef, StringRef, StringRef, int64_t>,
+           KnownDotAlgorithm>
+      knownDotAlgorithms{
+          {{f16, f16, f16, 1}, KnownDotAlgorithm::F16_F16_F16},
+          {{f16, f16, f32, 1}, KnownDotAlgorithm::F16_F16_F32},
+          {{bf16, bf16, bf16, 1}, KnownDotAlgorithm::BF16_BF16_BF16},
+          {{bf16, bf16, f32, 1}, KnownDotAlgorithm::BF16_BF16_F32},
+          {{bf16, bf16, f32, 3}, KnownDotAlgorithm::BF16_BF16_F32_X3},
+          {{bf16, bf16, f32, 6}, KnownDotAlgorithm::BF16_BF16_F32_X6},
+          {{tf32, tf32, f32, 1}, KnownDotAlgorithm::TF32_TF32_F32},
+          {{tf32, tf32, f32, 3}, KnownDotAlgorithm::TF32_TF32_F32_X3},
+          {{f32, f32, f32, 1}, KnownDotAlgorithm::F32_F32_F32},
+          {{f64, f64, f64, 1}, KnownDotAlgorithm::F64_F64_F64},
+      };
+
+  auto algorithm = knownDotAlgorithms.find(key);
+  if (algorithm != knownDotAlgorithms.end()) {
+    LLVM_DEBUG(llvm::dbgs()
+               << "Found known dot algorithm: "
+               << static_cast<int64_t>(algorithm->second) << " "
+               << std::get<0>(key) << ", " << std::get<1>(key) << ", "
+               << std::get<2>(key) << ", " << std::get<3>(key) << "\n");
+    return algorithm->second;
+  }
+  return failure();
+}
+}  // namespace detail
+
+// Check if the combination of a dot algorithm struct is known.
+bool isKnownDotAlgorithm(Type lhsPrecisionType, Type rhsPrecisionType,
+                         Type accumulationType, int64_t lhsComponentCount,
+                         int64_t rhsComponentCount,
+                         int64_t numPrimitiveOperations,
+                         bool allowImpreciseAccumulation) {
+  return succeeded(detail::getKnownDotAlgorithm(
+      lhsPrecisionType, rhsPrecisionType, accumulationType, lhsComponentCount,
+      rhsComponentCount, numPrimitiveOperations, allowImpreciseAccumulation));
+}
+
 mlir::Speculation::Speculatability getShapedSpeculatability(
     Operation* op, int64_t shapeCount) {
   // If all inputs are static and the shape-related operands are constant
diff --ruN a/stablehlo/stablehlo/dialect/Base.h b/stablehlo/stablehlo/dialect/Base.h
--- stablehlo/stablehlo/dialect/Base.h
+++ stablehlo/stablehlo/dialect/Base.h
@@ -235,6 +235,43 @@
   virtual Attribute createTypeExtensions(ArrayRef<int64_t> bounds) const = 0;
 };
 
+namespace detail {
+
+// An enum which tracks known supported dot algorithm pairs.
+// Note this implementation is a detail for now and the APIs are likely to
+// change once HLO broadens support for LHS/RHS components and num primitive
+// operations.
+//
+// It is best to not rely on these values until the API solidifies.
+// Instead use `isKnownDotAlgorithm`.
+enum class KnownDotAlgorithm {
+  ANY_F8_ANY_F8_F32 = 1,
+  ANY_F8_ANY_F8_F32_FAST_ACCUM = 2,
+  F16_F16_F16 = 3,
+  F16_F16_F32 = 4,
+  BF16_BF16_BF16 = 5,
+  BF16_BF16_F32 = 6,
+  BF16_BF16_F32_X3 = 7,
+  BF16_BF16_F32_X6 = 8,
+  TF32_TF32_F32 = 9,
+  TF32_TF32_F32_X3 = 10,
+  F32_F32_F32 = 11,
+  F64_F64_F64 = 12,
+};
+
+FailureOr<KnownDotAlgorithm> getKnownDotAlgorithm(
+    Type lhsPrecisionType, Type rhsPrecisionType, Type accumulationType,
+    int64_t lhsComponentCount, int64_t rhsComponentCount,
+    int64_t numPrimitiveOperations, bool allowImpreciseAccumulation);
+}  // namespace detail
+
+// Check if the combination of a dot algorithm struct is known.
+bool isKnownDotAlgorithm(Type lhsPrecisionType, Type rhsPrecisionType,
+                         Type accumulationType, int64_t lhsComponentCount,
+                         int64_t rhsComponentCount,
+                         int64_t numPrimitiveOperations,
+                         bool allowImpreciseAccumulation);
+
 namespace bytecode {
 // Helper methods for bytecode
 // Enum reader and writer. Many attrs have a single enum type to serialize.
diff --ruN a/stablehlo/stablehlo/dialect/TypeInference.cpp b/stablehlo/stablehlo/dialect/TypeInference.cpp
--- stablehlo/stablehlo/dialect/TypeInference.cpp
+++ stablehlo/stablehlo/dialect/TypeInference.cpp
@@ -27,7 +27,9 @@
 #include <iterator>
 #include <numeric>
 #include <optional>
+#include <set>
 #include <string>
+#include <tuple>
 #include <type_traits>
 #include <utility>
 #include <vector>
@@ -4057,24 +4059,6 @@
     Type lhsPrecisionType, Type rhsPrecisionType, Type accumulationType,
     int64_t lhsComponentCount, int64_t rhsComponentCount,
     int64_t numPrimitiveOperations, bool allowImpreciseAccumulation) {
-  auto isValidType = [](Type t) {
-    // Only support float types for now
-    // This can be extended as needed, as the RFC was for general support, but
-    // only FP hardware support exists in the ecosystem today.
-    return llvm::isa<FloatTF32Type, Float8E4M3FNType, Float8E5M2Type,
-                     Float8E4M3FNUZType, Float8E4M3B11FNUZType,
-                     Float8E5M2FNUZType, BFloat16Type, Float16Type, Float32Type,
-                     Float64Type>(t);
-  };
-  // dot_general_i8
-  if (!isValidType(lhsPrecisionType))
-    return emitError() << "lhs precision type must be float";
-  // dot_general_i9
-  if (!isValidType(rhsPrecisionType))
-    return emitError() << "rhs precision type must be float";
-  // dot_general_i10
-  if (!isValidType(accumulationType))
-    return emitError() << "accumulation type must be float";
   // dot_general_c22
   if (lhsComponentCount < 1)
     return emitError() << "lhs component count must be positive";
@@ -4084,6 +4068,21 @@
   // dot_general_c24
   if (numPrimitiveOperations < 1)
     return emitError() << "num primitive operations must be positive";
+
+  // Best effort algorithm verification, support algorithm combinations
+  // known to be supported on some hardware, not necessarily the target hardware
+  // dot_general_i8, dot_general_i9, dot_general_i10
+  if (!isKnownDotAlgorithm(lhsPrecisionType, rhsPrecisionType, accumulationType,
+                           lhsComponentCount, rhsComponentCount,
+                           numPrimitiveOperations, allowImpreciseAccumulation))
+    return emitError()
+           << "dot algorithm not known to be supported on any hardware: "
+           << "{lhs:" << lhsPrecisionType << ", rhs:" << rhsPrecisionType
+           << ", accum:" << accumulationType
+           << ", lhs_components:" << lhsComponentCount
+           << ", rhs_components:" << rhsComponentCount
+           << ", primitive_ops:" << numPrimitiveOperations
+           << ", imprecise:" << allowImpreciseAccumulation << "}";
   return success();
 }
 
diff --ruN a/stablehlo/stablehlo/dialect/Version.cpp b/stablehlo/stablehlo/dialect/Version.cpp
--- stablehlo/stablehlo/dialect/Version.cpp
+++ stablehlo/stablehlo/dialect/Version.cpp
@@ -72,6 +72,22 @@
   return failure();
 }
 
+Version Version::fromCompatibilityRequirement(
+    CompatibilityRequirement requirement) {
+  // Compatibility requirement versions can be updated as needed, as long as the
+  // version satisifies the requirement.
+  switch (requirement) {
+    case CompatibilityRequirement::NONE:
+      return Version::getCurrentVersion();
+    case CompatibilityRequirement::WEEK_4:
+      return Version(1, 3, 0);  // v1.3.0 - Jul 15, 2024
+    case CompatibilityRequirement::WEEK_12:
+      return Version(1, 0, 0);  // v1.0.0 - May 14, 2024
+    case CompatibilityRequirement::MAX:
+      return Version::getMinimumVersion();
+  }
+}
+
 mlir::Diagnostic& operator<<(mlir::Diagnostic& diag, const Version& version) {
   return diag << version.toString();
 }
diff --ruN a/stablehlo/stablehlo/dialect/Version.h b/stablehlo/stablehlo/dialect/Version.h
--- stablehlo/stablehlo/dialect/Version.h
+++ stablehlo/stablehlo/dialect/Version.h
@@ -43,6 +43,31 @@
   /// Return a Version representing the minimum supported VHLO dialect version.
   static Version getMinimumVersion() { return Version(0, 9, 0); }
 
+  // CompatibilityRequirement is used to get a viable target version to use for
+  // `serializePortableArtifact` given a compatibility requirement specified as
+  // a duration.
+  //
+  // New enum values can be added per use case.
+  //
+  // Values represent a minimum requirement, i.e. MONTH_3 may return a 4 month
+  // old version, the specific implementation detail can be updated at any time
+  // by the community as long as it satisfies the requirement.
+  //
+  // Given that integration into XLA is not immediate, coarse intervals work
+  // better than providing a specific date.
+  enum class CompatibilityRequirement {
+    NONE = 0,     // No compat requirement, use latest version.
+    WEEK_4 = 1,   // 1 month requirement
+    WEEK_12 = 2,  // 3 month requirement
+    MAX = 3,      // Maximum compat, use minimum supported version
+  };
+
+  // Get a viable target version to use for `serializePortableArtifact` for a
+  // given compatibility requirement. See `CompatibilityRequirement` for
+  // details.
+  static Version fromCompatibilityRequirement(
+      CompatibilityRequirement requirement);
+
   /// Return the MLIR Bytecode Format associated with the version instance.
   /// Returns failure if version is not in compatibility window.
   FailureOr<int64_t> getBytecodeVersion() const;
diff --ruN a/stablehlo/stablehlo/dialect/VhloDialect.td b/stablehlo/stablehlo/dialect/VhloDialect.td
--- stablehlo/stablehlo/dialect/VhloDialect.td
+++ stablehlo/stablehlo/dialect/VhloDialect.td
@@ -39,6 +39,7 @@
       0.19.0: Introduce `composite` operation.
       0.20.0: Remove `padding` attribute from `dynamic_conv`.
       1.0.0: Increase compatibility guarantees to 5 years backward, 2 years forward (no functional changes relative to 0.20.0).
+      1.1.0: Add gather/scatter batching dimensions.
       1.2.0: Introduce `si2` and `ui2` types.
       1.3.0: Extend `custom_call` op `backend_config` to support `DictionaryAttr`.
       1.4.0: Add `tan` op to StableHLO opset.
diff --ruN a/stablehlo/stablehlo/integrations/c/CMakeLists.txt b/stablehlo/stablehlo/integrations/c/CMakeLists.txt
--- stablehlo/stablehlo/integrations/c/CMakeLists.txt
+++ stablehlo/stablehlo/integrations/c/CMakeLists.txt
@@ -33,14 +33,24 @@
 
 add_mlir_public_c_api_library(StablehloCAPI
   PARTIAL_SOURCES_INTENDED
+  StablehloApi.cpp
   StablehloAttributes.cpp
   StablehloDialect.cpp
   StablehloPasses.cpp
   StablehloTypes.cpp
 
   LINK_LIBS PUBLIC
+  LLVMSupport
+  MLIRCAPIIR
+  MLIRIR
+  MLIRSupport
   StablehloOps
   StablehloPasses
+  StablehloPortableApi
+  StablehloReferenceApi
+  StablehloReferenceConfiguration
+  StablehloSerialization
+  Version
 )
 
 add_mlir_public_c_api_library(VhloCAPI
diff --ruN a/stablehlo/stablehlo/integrations/c/StablehloApi.cpp b/stablehlo/stablehlo/integrations/c/StablehloApi.cpp
--- stablehlo/stablehlo/integrations/c/StablehloApi.cpp
+++ stablehlo/stablehlo/integrations/c/StablehloApi.cpp
@@ -0,0 +1,138 @@
+/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.
+   Copyright 2022 The StableHLO Authors.
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+    http://www.apache.org/licenses/LICENSE-2.0
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "stablehlo/integrations/c/StablehloApi.h"
+
+#include <vector>
+
+#include "llvm/Support/Casting.h"
+#include "llvm/Support/ErrorHandling.h"
+#include "mlir-c/BuiltinAttributes.h"
+#include "mlir-c/IR.h"
+#include "mlir-c/Support.h"
+#include "mlir/CAPI/IR.h"
+#include "mlir/CAPI/Support.h"
+#include "mlir/CAPI/Utils.h"
+#include "mlir/IR/BuiltinAttributes.h"
+#include "mlir/Support/LLVM.h"
+#include "stablehlo/api/PortableApi.h"
+#include "stablehlo/dialect/Serialization.h"
+#include "stablehlo/dialect/Version.h"
+#include "stablehlo/reference/Api.h"
+#include "stablehlo/reference/Configuration.h"
+
+int stablehloGetApiVersion() { return mlir::stablehlo::getApiVersion(); }
+
+mlir::vhlo::Version::CompatibilityRequirement unwrapCompatibilityRequirement(
+    MlirStablehloCompatibilityRequirement requirement) {
+  switch (requirement) {
+    case MlirStablehloCompatibilityRequirement::NONE:
+      return mlir::vhlo::Version::CompatibilityRequirement::NONE;
+    case MlirStablehloCompatibilityRequirement::WEEK_4:
+      return mlir::vhlo::Version::CompatibilityRequirement::WEEK_4;
+    case MlirStablehloCompatibilityRequirement::WEEK_12:
+      return mlir::vhlo::Version::CompatibilityRequirement::WEEK_12;
+    case MlirStablehloCompatibilityRequirement::MAX:
+      return mlir::vhlo::Version::CompatibilityRequirement::MAX;
+  }
+  llvm::report_fatal_error("unhandled compatibility requirement");
+}
+
+void stablehloVersionFromCompatibilityRequirement(
+    MlirStablehloCompatibilityRequirement requirement,
+    MlirStringCallback callback, void *userData) {
+  mlir::detail::CallbackOstream stream(callback, userData);
+  stream << mlir::vhlo::Version::fromCompatibilityRequirement(
+      unwrapCompatibilityRequirement(requirement));
+}
+
+void stablehloGetCurrentVersion(MlirStringCallback callback, void *userData) {
+  mlir::detail::CallbackOstream stream(callback, userData);
+  stream << mlir::stablehlo::getCurrentVersion();
+}
+
+void stablehloGetMinimumVersion(MlirStringCallback callback, void *userData) {
+  mlir::detail::CallbackOstream stream(callback, userData);
+  stream << mlir::stablehlo::getMinimumVersion();
+}
+
+MlirLogicalResult stablehloGetSmallerVersion(MlirStringRef version1,
+                                             MlirStringRef version2,
+                                             MlirStringCallback callback,
+                                             void *userData) {
+  mlir::detail::CallbackOstream stream(callback, userData);
+  auto result =
+      mlir::stablehlo::getSmallerVersion(unwrap(version1), unwrap(version2));
+  if (mlir::failed(result)) return mlirLogicalResultFailure();
+  stream << mlir::stablehlo::getSmallerVersion(unwrap(version1),
+                                               unwrap(version2));
+  return mlirLogicalResultSuccess();
+}
+
+MlirLogicalResult stablehloSerializePortableArtifact(
+    MlirModule moduleStr, MlirStringRef targetVersion,
+    MlirStringCallback callback, void *userData) {
+  mlir::detail::CallbackOstream stream(callback, userData);
+  if (failed(mlir::stablehlo::serializePortableArtifact(
+          unwrap(moduleStr), unwrap(targetVersion), stream)))
+    return mlirLogicalResultFailure();
+  return mlirLogicalResultSuccess();
+}
+
+MlirLogicalResult stablehloSerializePortableArtifact(
+    MlirStringRef moduleStr, MlirStringRef targetVersion,
+    MlirStringCallback callback, void *userData) {
+  mlir::detail::CallbackOstream stream(callback, userData);
+  if (failed(mlir::stablehlo::serializePortableArtifact(
+          unwrap(moduleStr), unwrap(targetVersion), stream)))
+    return mlirLogicalResultFailure();
+  return mlirLogicalResultSuccess();
+}
+
+MlirLogicalResult stablehloDeserializePortableArtifact(
+    MlirStringRef artifactStr, MlirStringCallback callback, void *userData) {
+  mlir::detail::CallbackOstream stream(callback, userData);
+  if (failed(mlir::stablehlo::deserializePortableArtifact(unwrap(artifactStr),
+                                                          stream)))
+    return mlirLogicalResultFailure();
+  return mlirLogicalResultSuccess();
+}
+
+MlirModule stablehloDeserializePortableArtifact(MlirStringRef artifactStr,
+                                                MlirContext ctx) {
+  return wrap(mlir::stablehlo::deserializePortableArtifact(unwrap(artifactStr),
+                                                           unwrap(ctx))
+                  .release());
+}
+
+MlirAttribute stablehloEvalModule(MlirModule module, int nArgs,
+                                  MlirAttribute const *args, int *errorCode) {
+  std::vector<mlir::DenseElementsAttr> inputs;
+  inputs.reserve(nArgs);
+  for (int i = 0; i < nArgs; ++i) {
+    inputs.push_back(llvm::cast<mlir::DenseElementsAttr>(unwrap(args[i])));
+  }
+  mlir::stablehlo::InterpreterConfiguration config;
+  mlir::FailureOr<llvm::SmallVector<mlir::DenseElementsAttr>> results =
+      mlir::stablehlo::evalModule(unwrap(module), inputs, config);
+  if (mlir::failed(results)) {
+    *errorCode = 1;
+    return MlirAttribute{nullptr};
+  }
+  std::vector<MlirAttribute> resultsVec;
+  for (const auto &result : results.value()) {
+    resultsVec.push_back(wrap(result));
+  }
+  return mlirArrayAttrGet(mlirModuleGetContext(module), resultsVec.size(),
+                          resultsVec.data());
+}
diff --ruN a/stablehlo/stablehlo/integrations/c/StablehloApi.h b/stablehlo/stablehlo/integrations/c/StablehloApi.h
--- stablehlo/stablehlo/integrations/c/StablehloApi.h
+++ stablehlo/stablehlo/integrations/c/StablehloApi.h
@@ -0,0 +1,123 @@
+/* Copyright 2024 The StableHLO Authors.
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+    http://www.apache.org/licenses/LICENSE-2.0
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef STABLEHLO_INTEGRATIONS_C_STABLEHLOAPI_H_
+#define STABLEHLO_INTEGRATIONS_C_STABLEHLOAPI_H_
+
+#include "mlir-c/IR.h"
+#include "mlir-c/Support.h"
+
+// Get the current StableHLO API version.
+//
+// This value is incremented as needed to help integrate API changes.
+MLIR_CAPI_EXPORTED int stablehloGetApiVersion();
+
+typedef enum MlirStablehloCompatibilityRequirement {
+  NONE = 0,
+  WEEK_4 = 1,
+  WEEK_12 = 2,
+  MAX = 3
+} MlirStablehloCompatibilityRequirement;
+
+// Returns a StringAtt with the version of StableHLO that satisfies the
+// compatibility requirement, which is owned by ctx.
+MLIR_CAPI_EXPORTED void stablehloVersionFromCompatibilityRequirement(
+    MlirStablehloCompatibilityRequirement requirement,
+    MlirStringCallback callback, void* userData);
+
+// Get the current StableHLO version.
+//
+// This value can be used as the `targetVersion` argument to
+// `serializePortableArtifact`.
+MLIR_CAPI_EXPORTED void stablehloGetCurrentVersion(MlirStringCallback callback,
+                                                   void* userData);
+
+// Get the minimum supported StableHLO version.
+//
+// This value can be used as the `targetVersion` argument to
+// `serializePortableArtifact`.
+//
+// Each StableHLO version `producer_version` has a compatibility window,
+// i.e. range of versions [`consumer_version_min`, `consumer_version_max`],
+// where StableHLO portable artifacts serialized by `producer_version`
+// can be deserialized by `consumer_version` within the window.
+// See https://github.com/openxla/stablehlo/blob/main/docs/compatibility.md
+// for the exact extent of these compatibility guarantees.
+//
+// This function returns `consumer_version_min` for the current StableHLO
+// version. It can be used maximize forward compatibility, i.e. to maximize how
+// far into the past we can go and still have the payloads produced by
+// `serializePortableArtifact` compatible with potential consumers from the past
+MLIR_CAPI_EXPORTED void stablehloGetMinimumVersion(MlirStringCallback callback,
+                                                   void* userData);
+
+// For two given version strings, return the smaller version.
+// Returns failure if either version is not a valid version string.
+MLIR_CAPI_EXPORTED MlirLogicalResult
+stablehloGetSmallerVersion(MlirStringRef version1, MlirStringRef version2,
+                           MlirStringCallback callback, void* userData);
+
+// Write a StableHLO program expressed as a string (either prettyprinted MLIR
+// module or MLIR bytecode) to a portable artifact.
+// Can fail if `moduleStr` cannot be parsed, or if it cannot be expressed in the
+// `targetVersion` version of StableHLO, e.g. if it's using new or removed
+// features, or if it involves unsupported dialects.
+// Returns false on failure.
+MLIR_CAPI_EXPORTED MlirLogicalResult stablehloSerializePortableArtifact(
+    MlirStringRef moduleStr, MlirStringRef targetVersion,
+    MlirStringCallback callback, void* userData);
+
+// Write a StableHLO program expressed as a string (either prettyprinted MLIR
+// module or MLIR bytecode) to a portable artifact.
+// Can fail if `moduleStr` cannot be parsed, or if it cannot be expressed in the
+// `targetVersion` version of StableHLO, e.g. if it's using new or removed
+// features, or if it involves unsupported dialects.
+// Returns false on failure.
+MLIR_CAPI_EXPORTED MlirLogicalResult stablehloSerializePortableArtifact(
+    MlirModule moduleStr, MlirStringRef targetVersion,
+    MlirStringCallback callback, void* userData);
+
+// Read a StableHLO program from a portable artifact, returning the module as
+// MLIR bytecode. Note, this bytecode returned is not a portable artifact,
+// and has the stability of returning textual assembly format. Bytecode is
+// returned here since it is more compact and faster to read and write.
+// Can fail if `artifactStr` cannot be expressed in the current version of
+// StableHLO, e.g. if it's using incompatible features.
+// Returns false on failure.
+MLIR_CAPI_EXPORTED MlirLogicalResult stablehloDeserializePortableArtifact(
+    MlirStringRef artifactStr, MlirStringCallback callback, void* userData);
+
+// Read a StableHLO program from a portable artifact, returning the module as
+// MLIR bytecode. Note, this bytecode returned is not a portable artifact,
+// and has the stability of returning textual assembly format. Bytecode is
+// returned here since it is more compact and faster to read and write.
+// Can fail if `artifactStr` cannot be expressed in the current version of
+// StableHLO, e.g. if it's using incompatible features.
+//
+// Returns empty module on failure.
+MLIR_CAPI_EXPORTED MlirModule stablehloDeserializePortableArtifact(
+    MlirStringRef artifactStr, MlirContext ctx);
+
+// Call the Interpreter, returns MlirArrayAttr of dense element
+// MlirAttribute results
+MLIR_CAPI_EXPORTED MlirModule stablehloDeserializePortableArtifact(
+    MlirStringRef artifactStr, MlirContext ctx);
+
+// Entrypoint for calling the StableHLO reference interpreter.
+// Returns an array attribute of dense element attributes for results.
+// Sets error code to non-zero on failure.
+MLIR_CAPI_EXPORTED MlirAttribute stablehloEvalModule(MlirModule module,
+                                                     int nArgs,
+                                                     MlirAttribute const* args,
+                                                     int* errorCode);
+
+#endif  // STABLEHLO_INTEGRATIONS_C_STABLEHLOAPI_H_
diff --ruN a/stablehlo/stablehlo/integrations/c/StablehloDialect.h b/stablehlo/stablehlo/integrations/c/StablehloDialect.h
--- stablehlo/stablehlo/integrations/c/StablehloDialect.h
+++ stablehlo/stablehlo/integrations/c/StablehloDialect.h
@@ -14,6 +14,7 @@
 #ifndef STABLEHLO_INTEGRATIONS_C_STABLEHLO_DIALECT_H
 #define STABLEHLO_INTEGRATIONS_C_STABLEHLO_DIALECT_H
 
+#include "mlir-c/IR.h"
 #include "mlir-c/RegisterEverything.h"
 
 #ifdef __cplusplus
diff --ruN a/stablehlo/stablehlo/integrations/python/CMakeLists.txt b/stablehlo/stablehlo/integrations/python/CMakeLists.txt
--- stablehlo/stablehlo/integrations/python/CMakeLists.txt
+++ stablehlo/stablehlo/integrations/python/CMakeLists.txt
@@ -110,15 +110,11 @@
   MODULE_NAME _stablehlo
   ADD_TO_PARENT StablehloPythonExtensions
   SOURCES
+    StablehloApi.cpp
     StablehloModule.cpp
-    PortableApi.cpp
   EMBED_CAPI_LINK_LIBS
     StablehloCAPI
   PRIVATE_LINK_LIBS
-    StablehloPasses
-    StablehloPortableApi
-    StablehloReferenceApi
-    StablehloSerialization
     LLVMSupport
 )
 
diff --ruN a/stablehlo/stablehlo/integrations/python/PortableApi.cpp b/stablehlo/stablehlo/integrations/python/PortableApi.cpp
--- stablehlo/stablehlo/integrations/python/PortableApi.cpp
+++ stablehlo/stablehlo/integrations/python/PortableApi.cpp
@@ -1,85 +0,0 @@
-/* Copyright 2023 The TensorFlow Authors. All Rights Reserved.
-
-Licensed under the Apache License, Version 2.0 (the "License");
-you may not use this file except in compliance with the License.
-You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-Unless required by applicable law or agreed to in writing, software
-distributed under the License is distributed on an "AS IS" BASIS,
-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-See the License for the specific language governing permissions and
-limitations under the License.
-==============================================================================*/
-
-#include "stablehlo/integrations/python/PortableApi.h"
-
-#include <string>
-
-#include "stablehlo/api/PortableApi.h"
-
-namespace py = pybind11;
-
-namespace mlir {
-namespace stablehlo {
-
-void AddPortableApi(py::module& m) {
-  //
-  // Utility APIs.
-  //
-
-  m.def("get_api_version", []() { return getApiVersion(); });
-
-  m.def(
-      "get_smaller_version",
-      [](std::string version1, std::string version2) -> py::str {
-        std::string result;
-        if (failed(getSmallerVersion(version1, version2, result))) {
-          PyErr_SetString(PyExc_ValueError,
-                          "failed to convert version to stablehlo version");
-          return "";
-        }
-        return result;
-      },
-      py::arg("version1"), py::arg("version2"));
-
-  //
-  // Serialization APIs.
-  //
-
-  m.def("get_current_version", []() { return getCurrentVersion(); });
-
-  m.def("get_minimum_version", []() { return getMinimumVersion(); });
-
-  m.def(
-      "serialize_portable_artifact",
-      [](std::string moduleStr, std::string targetVersion) -> py::bytes {
-        std::string buffer;
-        llvm::raw_string_ostream os(buffer);
-        if (failed(serializePortableArtifact(moduleStr, targetVersion, os))) {
-          PyErr_SetString(PyExc_ValueError, "failed to serialize module");
-          return "";
-        }
-
-        return py::bytes(buffer);
-      },
-      py::arg("module_str"), py::arg("target_version"));
-
-  m.def(
-      "deserialize_portable_artifact",
-      [](std::string artifactStr) -> py::bytes {
-        std::string buffer;
-        llvm::raw_string_ostream os(buffer);
-        if (failed(deserializePortableArtifact(artifactStr, os))) {
-          PyErr_SetString(PyExc_ValueError, "failed to deserialize module");
-          return "";
-        }
-
-        return py::bytes(buffer);
-      },
-      py::arg("artifact_str"));
-}
-
-}  // namespace stablehlo
-}  // namespace mlir
diff --ruN a/stablehlo/stablehlo/integrations/python/PortableApi.h b/stablehlo/stablehlo/integrations/python/PortableApi.h
--- stablehlo/stablehlo/integrations/python/PortableApi.h
+++ stablehlo/stablehlo/integrations/python/PortableApi.h
@@ -1,31 +0,0 @@
-/* Copyright 2023 The StableHLO Authors.
-
-Licensed under the Apache License, Version 2.0 (the "License");
-you may not use this file except in compliance with the License.
-You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-Unless required by applicable law or agreed to in writing, software
-distributed under the License is distributed on an "AS IS" BASIS,
-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-See the License for the specific language governing permissions and
-limitations under the License.
-==============================================================================*/
-
-#ifndef STABLEHLO_INTEGRATIONS_PYTHON_API_PORTABLEAPI_H
-#define STABLEHLO_INTEGRATIONS_PYTHON_API_PORTABLEAPI_H
-
-#include "pybind11/pybind11.h"
-
-namespace mlir {
-namespace stablehlo {
-
-// Add portable API to the pybind11 module.
-// Signatures of these APIs have no dependency on MLIR.
-void AddPortableApi(pybind11::module& m);
-
-}  // namespace stablehlo
-}  // namespace mlir
-
-#endif  // STABLEHLO_INTEGRATIONS_PYTHON_API_PORTABLEAPI_H
diff --ruN a/stablehlo/stablehlo/integrations/python/StablehloApi.cpp b/stablehlo/stablehlo/integrations/python/StablehloApi.cpp
--- stablehlo/stablehlo/integrations/python/StablehloApi.cpp
+++ stablehlo/stablehlo/integrations/python/StablehloApi.cpp
@@ -0,0 +1,263 @@
+/* Copyright 2023 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "stablehlo/integrations/python/StablehloApi.h"
+
+#include <string>
+#include <string_view>
+
+#include "mlir-c/BuiltinAttributes.h"
+#include "mlir-c/IR.h"
+#include "mlir-c/Support.h"
+#include "mlir/Bindings/Python/PybindAdaptors.h"
+#include "mlir/CAPI/IR.h"
+#include "mlir/CAPI/Support.h"
+#include "mlir/CAPI/Utils.h"
+#include "stablehlo/integrations/c/StablehloApi.h"
+
+namespace py = pybind11;
+
+namespace mlir {
+namespace stablehlo {
+
+// A helper class that implements `MlirStringCallback` by printing parts into a
+// C++ string.
+class StringWriterHelper {
+ public:
+  StringWriterHelper() : ss_(s_) {}
+
+  static MlirStringCallback getMlirStringCallback() {
+    return [](MlirStringRef string_ref, void *user_data) {
+      auto *helper = static_cast<StringWriterHelper *>(user_data);
+      helper->ss_ << llvm::StringRef(string_ref.data, string_ref.length);
+    };
+  }
+
+  void *getUserData() { return static_cast<void *>(this); }
+
+  const std::string &toString() {
+    ss_.flush();
+    return s_;
+  }
+
+ private:
+  std::string s_;
+  llvm::raw_string_ostream ss_;
+};
+
+static MlirStringRef toMlirStringRef(const std::string &s) {
+  return mlirStringRefCreate(s.data(), s.size());
+}
+
+static MlirStringRef toMlirStringRef(std::string_view s) {
+  return mlirStringRefCreate(s.data(), s.size());
+}
+
+void AddStablehloApi(py::module& m) {
+  //
+  // Utility APIs.
+  //
+  py::enum_<MlirStablehloCompatibilityRequirement>(
+      m, "StablehloCompatibilityRequirement")
+      .value("NONE", MlirStablehloCompatibilityRequirement::NONE)
+      .value("WEEK_4", MlirStablehloCompatibilityRequirement::WEEK_4)
+      .value("WEEK_12", MlirStablehloCompatibilityRequirement::WEEK_12)
+      .value("MAX", MlirStablehloCompatibilityRequirement::MAX);
+
+  m.def("get_version_from_compatibility_requirement",
+        [](MlirStablehloCompatibilityRequirement requirement) -> py::str {
+          StringWriterHelper accumulator;
+          stablehloVersionFromCompatibilityRequirement(
+              requirement, accumulator.getMlirStringCallback(),
+              accumulator.getUserData());
+          return accumulator.toString();
+        },
+       py::arg("requirement"));
+
+  //
+  // Serialization APIs.
+  //
+  m.def(
+      "serialize_portable_artifact",
+      [](MlirModule module, std::string_view target) -> py::bytes {
+        StringWriterHelper accumulator;
+        if (mlirLogicalResultIsFailure(stablehloSerializePortableArtifact(
+                module, toMlirStringRef(target),
+                accumulator.getMlirStringCallback(),
+                accumulator.getUserData()))) {
+          PyErr_SetString(PyExc_ValueError, "failed to serialize module");
+          return "";
+        }
+
+        return py::bytes(accumulator.toString());
+      },
+      py::arg("module"), py::arg("target"));
+
+  m.def(
+      "deserialize_portable_artifact",
+      [](MlirContext context, std::string_view artifact) -> MlirModule {
+        auto module = stablehloDeserializePortableArtifact(
+            toMlirStringRef(artifact), context);
+        if (mlirModuleIsNull(module)) {
+          PyErr_SetString(PyExc_ValueError, "failed to deserialize module");
+          return {};
+        }
+        return module;
+      },
+      py::arg("context"), py::arg("artifact"));
+
+  //
+  // Reference APIs
+  //
+  m.def(
+      "eval_module",
+      [](MlirModule module,
+         std::vector<MlirAttribute> &args) -> std::vector<MlirAttribute> {
+        for (auto arg : args) {
+          if (!mlirAttributeIsADenseElements(arg)) {
+            PyErr_SetString(PyExc_ValueError,
+                            "input args must be DenseElementsAttr");
+            return {};
+          }
+        }
+
+        int errorCode(0);
+        MlirAttribute resultArrayAttr = stablehloEvalModule(
+            module, static_cast<int>(args.size()), args.data(), &errorCode);
+
+        if (errorCode != 0) {
+          PyErr_SetString(PyExc_ValueError, "interpreter failed");
+          return {};
+        }
+
+        std::vector<MlirAttribute> pyResults;
+        for (int i = 0; i < mlirArrayAttrGetNumElements(resultArrayAttr); i++) {
+          pyResults.push_back(mlirArrayAttrGetElement(resultArrayAttr, i));
+        }
+        return pyResults;
+      },
+      py::arg("module"), py::arg("args"));
+
+  // Portable API is a subset of StableHLO API
+  AddPortableApi(m);
+}
+
+void AddPortableApi(py::module &m) {
+  //
+  // Utility APIs.
+  //
+  m.def("get_api_version", []() { return stablehloGetApiVersion(); });
+
+  m.def(
+      "get_smaller_version",
+      [](const std::string &version1, const std::string &version2) -> py::str {
+        StringWriterHelper accumulator;
+        if (mlirLogicalResultIsFailure(stablehloGetSmallerVersion(
+                toMlirStringRef(version1), toMlirStringRef(version2),
+                accumulator.getMlirStringCallback(),
+                accumulator.getUserData()))) {
+          PyErr_SetString(PyExc_ValueError,
+                          "failed to convert version to stablehlo version");
+          return "";
+        }
+        return accumulator.toString();
+      },
+      py::arg("version1"), py::arg("version2"));
+
+  m.def("get_current_version", []() -> py::str {
+    StringWriterHelper accumulator;
+    stablehloGetCurrentVersion(accumulator.getMlirStringCallback(),
+                               accumulator.getUserData());
+    return accumulator.toString();
+  });
+
+  m.def("get_minimum_version", []() -> py::str {
+    StringWriterHelper accumulator;
+    stablehloGetMinimumVersion(accumulator.getMlirStringCallback(),
+                               accumulator.getUserData());
+    return accumulator.toString();
+  });
+
+  //
+  // Serialization APIs (deprecated, use _str methods).
+  //
+  m.def(
+      "serialize_portable_artifact",
+      [](std::string_view moduleStrOrBytecode,
+         std::string_view targetVersion) -> py::bytes {
+        StringWriterHelper accumulator;
+        if (mlirLogicalResultIsFailure(stablehloSerializePortableArtifact(
+                toMlirStringRef(moduleStrOrBytecode),
+                toMlirStringRef(targetVersion),
+                accumulator.getMlirStringCallback(),
+                accumulator.getUserData()))) {
+          PyErr_SetString(PyExc_ValueError, "failed to serialize module");
+          return "";
+        }
+        return py::bytes(accumulator.toString());
+      },
+      py::arg("module_str"), py::arg("target_version"));
+
+  m.def(
+      "deserialize_portable_artifact",
+      [](std::string_view artifact) -> py::bytes {
+        StringWriterHelper accumulator;
+        if (mlirLogicalResultIsFailure(stablehloDeserializePortableArtifact(
+                toMlirStringRef(artifact), accumulator.getMlirStringCallback(),
+                accumulator.getUserData()))) {
+          PyErr_SetString(PyExc_ValueError, "failed to deserialize module");
+          return "";
+        }
+        return py::bytes(accumulator.toString());
+      },
+      py::arg("artifact_str"));
+
+  //
+  // Serialization APIs.
+  //
+  m.def(
+      "serialize_portable_artifact_str",
+      [](std::string_view moduleStrOrBytecode,
+         std::string_view targetVersion) -> py::bytes {
+        StringWriterHelper accumulator;
+        if (mlirLogicalResultIsFailure(stablehloSerializePortableArtifact(
+                toMlirStringRef(moduleStrOrBytecode),
+                toMlirStringRef(targetVersion),
+                accumulator.getMlirStringCallback(),
+                accumulator.getUserData()))) {
+          PyErr_SetString(PyExc_ValueError, "failed to serialize module");
+          return "";
+        }
+        return py::bytes(accumulator.toString());
+      },
+      py::arg("module_str"), py::arg("target_version"));
+
+  m.def(
+      "deserialize_portable_artifact_str",
+      [](std::string_view artifact) -> py::bytes {
+        StringWriterHelper accumulator;
+        if (mlirLogicalResultIsFailure(stablehloDeserializePortableArtifact(
+                toMlirStringRef(artifact), accumulator.getMlirStringCallback(),
+                accumulator.getUserData()))) {
+          PyErr_SetString(PyExc_ValueError, "failed to deserialize module");
+          return "";
+        }
+        return py::bytes(accumulator.toString());
+      },
+      py::arg("artifact_str"));
+}
+
+}  // namespace stablehlo
+}  // namespace mlir
diff --ruN a/stablehlo/stablehlo/integrations/python/StablehloApi.h b/stablehlo/stablehlo/integrations/python/StablehloApi.h
--- stablehlo/stablehlo/integrations/python/StablehloApi.h
+++ stablehlo/stablehlo/integrations/python/StablehloApi.h
@@ -0,0 +1,37 @@
+/* Copyright 2023 The StableHLO Authors.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef STABLEHLO_INTEGRATIONS_PYTHON_API_STABLEHLOAPI_H
+#define STABLEHLO_INTEGRATIONS_PYTHON_API_STABLEHLOAPI_H
+
+#include "pybind11/pybind11.h"
+
+namespace mlir {
+namespace stablehlo {
+
+// Add StableHLO APIs to the pybind11 module.
+// Signatures of these APIs have no dependency on C++ MLIR types and all must
+// use C API passthrough.
+void AddStablehloApi(pybind11::module& m);
+
+// Adds a subset of the StableHLO API that doesn't use MLIR in any definitions,
+// and is methods only, introducing no new objects / enums to avoid potential
+// redefinition issues in complex build environments.
+void AddPortableApi(pybind11::module& m);
+
+}  // namespace stablehlo
+}  // namespace mlir
+
+#endif  // STABLEHLO_INTEGRATIONS_PYTHON_API_STABLEHLOAPI_H
diff --ruN a/stablehlo/stablehlo/integrations/python/StablehloModule.cpp b/stablehlo/stablehlo/integrations/python/StablehloModule.cpp
--- stablehlo/stablehlo/integrations/python/StablehloModule.cpp
+++ stablehlo/stablehlo/integrations/python/StablehloModule.cpp
@@ -14,16 +14,13 @@
 #include <vector>
 
 #include "mlir-c/IR.h"
+#include "mlir-c/Support.h"
 #include "mlir/Bindings/Python/PybindAdaptors.h"
-#include "mlir/CAPI/IR.h"
-#include "mlir/IR/BuiltinAttributes.h"
-#include "stablehlo/dialect/Serialization.h"
 #include "stablehlo/integrations/c/StablehloAttributes.h"
 #include "stablehlo/integrations/c/StablehloDialect.h"
 #include "stablehlo/integrations/c/StablehloPasses.h"
 #include "stablehlo/integrations/c/StablehloTypes.h"
-#include "stablehlo/integrations/python/PortableApi.h"
-#include "stablehlo/reference/Api.h"
+#include "stablehlo/integrations/python/StablehloApi.h"
 
 namespace py = pybind11;
 
@@ -533,73 +530,7 @@
       });
 
   //
-  // Portable APIs
-  //
-  mlir::stablehlo::AddPortableApi(m);
-
-  //
-  // Reference APIs
-  //
-  m.def(
-      "eval_module",
-      [](MlirModule module,
-         std::vector<MlirAttribute> &args) -> std::vector<MlirAttribute> {
-        std::vector<mlir::DenseElementsAttr> inputs;
-        for (auto arg : args) {
-          auto attr = llvm::dyn_cast<mlir::DenseElementsAttr>(unwrap(arg));
-          if (!attr) {
-            PyErr_SetString(PyExc_ValueError,
-                            "input args must be DenseElementsAttr");
-            return {};
-          }
-          inputs.push_back(attr);
-        }
-
-        mlir::stablehlo::InterpreterConfiguration config;
-        auto results =
-            mlir::stablehlo::evalModule(unwrap(module), inputs, config);
-        if (failed(results)) {
-          PyErr_SetString(PyExc_ValueError, "interpreter failed");
-          return {};
-        }
-
-        std::vector<MlirAttribute> pyResults;
-        for (auto res : *results) pyResults.push_back(wrap(res));
-        return pyResults;
-      },
-      py::arg("module"), py::arg("args"));
-
-  //
-  // Serialization APIs.
-  //
-
-  m.def(
-      "serialize_portable_artifact",
-      [](MlirModule module, std::string target) -> py::bytes {
-        std::string buffer;
-        llvm::raw_string_ostream os(buffer);
-        if (failed(mlir::stablehlo::serializePortableArtifact(unwrap(module),
-                                                              target, os))) {
-          PyErr_SetString(PyExc_ValueError, "failed to serialize module");
-          return "";
-        }
-
-        return py::bytes(buffer);
-      },
-      py::arg("module"), py::arg("target"));
-
-  m.def(
-      "deserialize_portable_artifact",
-      [](MlirContext context, std::string artifact) -> MlirModule {
-        auto module = mlir::stablehlo::deserializePortableArtifact(
-            artifact, unwrap(context));
-
-        if (!module) {
-          PyErr_SetString(PyExc_ValueError, "failed to deserialize module");
-          return {};
-        }
-
-        return {module.release()};
-      },
-      py::arg("context"), py::arg("artifact"));
+  // StableHLO APIs
+  //
+  mlir::stablehlo::AddStablehloApi(m);
 }
diff --ruN a/stablehlo/stablehlo/integrations/python/tests/stablehlo.py b/stablehlo/stablehlo/integrations/python/tests/stablehlo.py
--- stablehlo/stablehlo/integrations/python/tests/stablehlo.py
+++ stablehlo/stablehlo/integrations/python/tests/stablehlo.py
@@ -245,6 +245,19 @@
 def test_minimum_version():
   curr_version = stablehlo.get_minimum_version()
   assert is_semver_format(curr_version)
+
+
+@run
+def test_version_requirements():
+  for req in (
+      stablehlo.StablehloCompatibilityRequirement.NONE,
+      stablehlo.StablehloCompatibilityRequirement.WEEK_4,
+      stablehlo.StablehloCompatibilityRequirement.WEEK_12,
+      stablehlo.StablehloCompatibilityRequirement.MAX,
+  ):
+    assert is_semver_format(
+        stablehlo.get_version_from_compatibility_requirement(req)
+    )
 
 
 ASM_FORMAT = """
@@ -321,8 +334,9 @@
     assert m is not None
     module_str = str(m)
     bytecode = module_to_bytecode(m)
-    serialized = stablehlo.serialize_portable_artifact(bytecode, curr_version)
-    deserialized = stablehlo.deserialize_portable_artifact(serialized)
+    serialized = stablehlo.serialize_portable_artifact_str(
+        bytecode, curr_version)
+    deserialized = stablehlo.deserialize_portable_artifact_str(serialized)
     deserialized_module = ir.Module.parse(deserialized)
     assert module_str == str(deserialized_module)
 
diff --ruN a/stablehlo/stablehlo/tests/interpret/dot_general.mlir b/stablehlo/stablehlo/tests/interpret/dot_general.mlir
--- stablehlo/stablehlo/tests/interpret/dot_general.mlir
+++ stablehlo/stablehlo/tests/interpret/dot_general.mlir
@@ -29,7 +29,7 @@
     algorithm = <
       lhs_precision_type = tf32,
       rhs_precision_type = tf32,
-      accumulation_type = tf32,
+      accumulation_type = f32,
       lhs_component_count = 1,
       rhs_component_count = 1,
       num_primitive_operations = 1,
diff --ruN a/stablehlo/stablehlo/tests/ops_dot_general_algorithms.mlir b/stablehlo/stablehlo/tests/ops_dot_general_algorithms.mlir
--- stablehlo/stablehlo/tests/ops_dot_general_algorithms.mlir
+++ stablehlo/stablehlo/tests/ops_dot_general_algorithms.mlir
@@ -0,0 +1,262 @@
+// RUN: stablehlo-opt %s -verify-diagnostics -split-input-file -allow-unregistered-dialect | FileCheck %s
+
+// CHECK-LABEL: func @dot_algorithm_f8_f8_f32
+func.func @dot_algorithm_f8_f8_f32(%arg0: tensor<2x2x2xf32>, %arg1: tensor<2x2x2xf32>) -> tensor<2x2x2xf32> {
+  %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
+    dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
+    precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>],
+    algorithm = #stablehlo.dot_algorithm<
+      lhs_precision_type = f8E4M3FNUZ,
+      rhs_precision_type = f8E4M3FNUZ,
+      accumulation_type = f32,
+      lhs_component_count = 1,
+      rhs_component_count = 1,
+      num_primitive_operations = 1,
+      allow_imprecise_accumulation = false
+    >
+  }> : (tensor<2x2x2xf32>, tensor<2x2x2xf32>) -> tensor<2x2x2xf32>  return %0 : tensor<2x2x2xf32>
+}
+
+// CHECK-LABEL: func @dot_algorithm_f8_f8_f32_fast_accum
+func.func @dot_algorithm_f8_f8_f32_fast_accum(%arg0: tensor<2x2x2xf32>, %arg1: tensor<2x2x2xf32>) -> tensor<2x2x2xf32> {
+  %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
+    dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
+    precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>],
+    algorithm = #stablehlo.dot_algorithm<
+      lhs_precision_type = f8E4M3FNUZ,
+      rhs_precision_type = f8E4M3FNUZ,
+      accumulation_type = f32,
+      lhs_component_count = 1,
+      rhs_component_count = 1,
+      num_primitive_operations = 1,
+      allow_imprecise_accumulation = true
+    >
+  }> : (tensor<2x2x2xf32>, tensor<2x2x2xf32>) -> tensor<2x2x2xf32>  return %0 : tensor<2x2x2xf32>
+}
+
+// CHECK-LABEL: func @dot_algorithm_f16_f16_f16
+func.func @dot_algorithm_f16_f16_f16(%arg0: tensor<2x2x2xf32>, %arg1: tensor<2x2x2xf32>) -> tensor<2x2x2xf32> {
+  %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
+    dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
+    precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>],
+    algorithm = #stablehlo.dot_algorithm<
+      lhs_precision_type = f16,
+      rhs_precision_type = f16,
+      accumulation_type = f16,
+      lhs_component_count = 1,
+      rhs_component_count = 1,
+      num_primitive_operations = 1,
+      allow_imprecise_accumulation = false
+    >
+  }> : (tensor<2x2x2xf32>, tensor<2x2x2xf32>) -> tensor<2x2x2xf32>  return %0 : tensor<2x2x2xf32>
+}
+
+// CHECK-LABEL: func @dot_algorithm_f16_f16_f32
+func.func @dot_algorithm_f16_f16_f32(%arg0: tensor<2x2x2xf32>, %arg1: tensor<2x2x2xf32>) -> tensor<2x2x2xf32> {
+  %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
+    dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
+    precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>],
+    algorithm = #stablehlo.dot_algorithm<
+      lhs_precision_type = f16,
+      rhs_precision_type = f16,
+      accumulation_type = f32,
+      lhs_component_count = 1,
+      rhs_component_count = 1,
+      num_primitive_operations = 1,
+      allow_imprecise_accumulation = false
+    >
+  }> : (tensor<2x2x2xf32>, tensor<2x2x2xf32>) -> tensor<2x2x2xf32>  return %0 : tensor<2x2x2xf32>
+}
+
+// CHECK-LABEL: func @dot_algorithm_bf16_bf16_bf16
+func.func @dot_algorithm_bf16_bf16_bf16(%arg0: tensor<2x2x2xbf16>, %arg1: tensor<2x2x2xbf16>) -> tensor<2x2x2xbf16> {
+  %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
+    dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
+    precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>],
+    algorithm = #stablehlo.dot_algorithm<
+      lhs_precision_type = bf16,
+      rhs_precision_type = bf16,
+      accumulation_type = bf16,
+      lhs_component_count = 1,
+      rhs_component_count = 1,
+      num_primitive_operations = 1,
+      allow_imprecise_accumulation = false
+    >
+  }> : (tensor<2x2x2xbf16>, tensor<2x2x2xbf16>) -> tensor<2x2x2xbf16>  return %0 : tensor<2x2x2xbf16>
+}
+
+// CHECK-LABEL: func @dot_algorithm_bf16_bf16_f32
+func.func @dot_algorithm_bf16_bf16_f32(%arg0: tensor<2x2x2xbf16>, %arg1: tensor<2x2x2xbf16>) -> tensor<2x2x2xbf16> {
+  %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
+    dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
+    precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>],
+    algorithm = #stablehlo.dot_algorithm<
+      lhs_precision_type = bf16,
+      rhs_precision_type = bf16,
+      accumulation_type = f32,
+      lhs_component_count = 1,
+      rhs_component_count = 1,
+      num_primitive_operations = 1,
+      allow_imprecise_accumulation = false
+    >
+  }> : (tensor<2x2x2xbf16>, tensor<2x2x2xbf16>) -> tensor<2x2x2xbf16>  return %0 : tensor<2x2x2xbf16>
+}
+
+// CHECK-LABEL: func @dot_algorithm_bf16_bf16_f32_x3
+func.func @dot_algorithm_bf16_bf16_f32_x3(%arg0: tensor<2x2x2xbf16>, %arg1: tensor<2x2x2xbf16>) -> tensor<2x2x2xbf16> {
+  %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
+    dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
+    precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>],
+    algorithm = #stablehlo.dot_algorithm<
+      lhs_precision_type = bf16,
+      rhs_precision_type = bf16,
+      accumulation_type = f32,
+      lhs_component_count = 1,
+      rhs_component_count = 1,
+      num_primitive_operations = 3,
+      allow_imprecise_accumulation = false
+    >
+  }> : (tensor<2x2x2xbf16>, tensor<2x2x2xbf16>) -> tensor<2x2x2xbf16>  return %0 : tensor<2x2x2xbf16>
+}
+
+// CHECK-LABEL: func @dot_algorithm_bf16_bf16_f32_x6
+func.func @dot_algorithm_bf16_bf16_f32_x6(%arg0: tensor<2x2x2xbf16>, %arg1: tensor<2x2x2xbf16>) -> tensor<2x2x2xbf16> {
+  %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
+    dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
+    precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>],
+    algorithm = #stablehlo.dot_algorithm<
+      lhs_precision_type = bf16,
+      rhs_precision_type = bf16,
+      accumulation_type = f32,
+      lhs_component_count = 1,
+      rhs_component_count = 1,
+      num_primitive_operations = 6,
+      allow_imprecise_accumulation = false
+    >
+  }> : (tensor<2x2x2xbf16>, tensor<2x2x2xbf16>) -> tensor<2x2x2xbf16>  return %0 : tensor<2x2x2xbf16>
+}
+
+// CHECK-LABEL: func @dot_algorithm_tf32_tf32_f32
+func.func @dot_algorithm_tf32_tf32_f32(%arg0: tensor<2x2x2xf32>, %arg1: tensor<2x2x2xf32>) -> tensor<2x2x2xf32> {
+  %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
+    dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
+    precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>],
+    algorithm = #stablehlo.dot_algorithm<
+      lhs_precision_type = tf32,
+      rhs_precision_type = tf32,
+      accumulation_type = f32,
+      lhs_component_count = 1,
+      rhs_component_count = 1,
+      num_primitive_operations = 1,
+      allow_imprecise_accumulation = false
+    >
+  }> : (tensor<2x2x2xf32>, tensor<2x2x2xf32>) -> tensor<2x2x2xf32>  return %0 : tensor<2x2x2xf32>
+}
+
+// CHECK-LABEL: func @dot_algorithm_tf32_tf32_f32_x3
+func.func @dot_algorithm_tf32_tf32_f32_x3(%arg0: tensor<2x2x2xf32>, %arg1: tensor<2x2x2xf32>) -> tensor<2x2x2xf32> {
+  %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
+    dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
+    precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>],
+    algorithm = #stablehlo.dot_algorithm<
+      lhs_precision_type = tf32,
+      rhs_precision_type = tf32,
+      accumulation_type = f32,
+      lhs_component_count = 1,
+      rhs_component_count = 1,
+      num_primitive_operations = 3,
+      allow_imprecise_accumulation = false
+    >
+  }> : (tensor<2x2x2xf32>, tensor<2x2x2xf32>) -> tensor<2x2x2xf32>  return %0 : tensor<2x2x2xf32>
+}
+
+// CHECK-LABEL: func @dot_algorithm_f32_f32_f32
+func.func @dot_algorithm_f32_f32_f32(%arg0: tensor<2x2x2xf32>, %arg1: tensor<2x2x2xf32>) -> tensor<2x2x2xf32> {
+  %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
+    dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
+    precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>],
+    algorithm = #stablehlo.dot_algorithm<
+      lhs_precision_type = f32,
+      rhs_precision_type = f32,
+      accumulation_type = f32,
+      lhs_component_count = 1,
+      rhs_component_count = 1,
+      num_primitive_operations = 1,
+      allow_imprecise_accumulation = false
+    >
+  }> : (tensor<2x2x2xf32>, tensor<2x2x2xf32>) -> tensor<2x2x2xf32>  return %0 : tensor<2x2x2xf32>
+}
+
+// CHECK-LABEL: func @dot_algorithm_f64_f64_f64
+func.func @dot_algorithm_f64_f64_f64(%arg0: tensor<2x2x2xf64>, %arg1: tensor<2x2x2xf64>) -> tensor<2x2x2xf64> {
+  %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
+    dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
+    precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>],
+    algorithm = #stablehlo.dot_algorithm<
+      lhs_precision_type = f64,
+      rhs_precision_type = f64,
+      accumulation_type = f64,
+      lhs_component_count = 1,
+      rhs_component_count = 1,
+      num_primitive_operations = 1,
+      allow_imprecise_accumulation = false
+    >
+  }> : (tensor<2x2x2xf64>, tensor<2x2x2xf64>) -> tensor<2x2x2xf64>  return %0 : tensor<2x2x2xf64>
+}
+
+// -----
+
+func.func @dot_algorithm_f32_f32_f32_l3(%arg0: tensor<2x2x2xf32>, %arg1: tensor<2x2x2xf32>) -> tensor<2x2x2xf32> {
+  // expected-error@+4 {{dot algorithm not known to be supported on any hardware: {lhs:'f32', rhs:'f32', accum:'f32', lhs_components:3, rhs_components:1, primitive_ops:1, imprecise:0}}}
+  %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
+    dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
+    precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>],
+    algorithm = #stablehlo.dot_algorithm<
+      lhs_precision_type = f32,
+      rhs_precision_type = f32,
+      accumulation_type = f32,
+      lhs_component_count = 3,
+      rhs_component_count = 1,
+      num_primitive_operations = 1,
+      allow_imprecise_accumulation = false
+    >
+  }> : (tensor<2x2x2xf32>, tensor<2x2x2xf32>) -> tensor<2x2x2xf32>  return %0 : tensor<2x2x2xf32>
+}
+
+// -----
+
+func.func @dot_algorithm_f32_f32_f32_r3(%arg0: tensor<2x2x2xf32>, %arg1: tensor<2x2x2xf32>) -> tensor<2x2x2xf32> {
+  // expected-error@+4 {{dot algorithm not known to be supported on any hardware: {lhs:'f32', rhs:'f32', accum:'f32', lhs_components:1, rhs_components:3, primitive_ops:1, imprecise:0}}}
+  %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
+    dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
+    precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>],
+    algorithm = #stablehlo.dot_algorithm<
+      lhs_precision_type = f32,
+      rhs_precision_type = f32,
+      accumulation_type = f32,
+      lhs_component_count = 1,
+      rhs_component_count = 3,
+      num_primitive_operations = 1,
+      allow_imprecise_accumulation = false
+    >
+  }> : (tensor<2x2x2xf32>, tensor<2x2x2xf32>) -> tensor<2x2x2xf32>  return %0 : tensor<2x2x2xf32>
+}
+
+// -----
+
+func.func @dot_algorithm_f32_f32_f32_imprecise(%arg0: tensor<2x2x2xf32>, %arg1: tensor<2x2x2xf32>) -> tensor<2x2x2xf32> {
+  // expected-error@+4 {{dot algorithm not known to be supported on any hardware: {lhs:'f32', rhs:'f32', accum:'f32', lhs_components:1, rhs_components:1, primitive_ops:1, imprecise:1}}}
+  %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
+    dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
+    precision_config = [#stablehlo<precision DEFAULT>, #stablehlo<precision DEFAULT>],
+    algorithm = #stablehlo.dot_algorithm<
+      lhs_precision_type = f32,
+      rhs_precision_type = f32,
+      accumulation_type = f32,
+      lhs_component_count = 1,
+      rhs_component_count = 1,
+      num_primitive_operations = 1,
+      allow_imprecise_accumulation = true
+    >
+  }> : (tensor<2x2x2xf32>, tensor<2x2x2xf32>) -> tensor<2x2x2xf32>  return %0 : tensor<2x2x2xf32>
+}
diff --ruN a/stablehlo/stablehlo/tests/ops_stablehlo.mlir b/stablehlo/stablehlo/tests/ops_stablehlo.mlir
--- stablehlo/stablehlo/tests/ops_stablehlo.mlir
+++ stablehlo/stablehlo/tests/ops_stablehlo.mlir
@@ -3334,7 +3334,7 @@
 // -----
 
 func.func @dot_general_i8(%arg0: tensor<2x2x2xi64>, %arg1: tensor<2x2x2xi64>) -> tensor<2x2x2xi64> {
-  // expected-error @+3 {{lhs precision type must be float}}
+  // expected-error @+3 {{dot algorithm not known to be supported on any hardware}}
   %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
     dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
     algorithm = #stablehlo.dot_algorithm<lhs_precision_type = i8, rhs_precision_type = f32, accumulation_type = f32, lhs_component_count = 1, rhs_component_count = 1, num_primitive_operations = 1, allow_imprecise_accumulation = false>
@@ -3344,7 +3344,7 @@
 // -----
 
 func.func @dot_general_i9(%arg0: tensor<2x2x2xi64>, %arg1: tensor<2x2x2xi64>) -> tensor<2x2x2xi64> {
-  // expected-error @+3 {{rhs precision type must be float}}
+  // expected-error @+3 {{dot algorithm not known to be supported on any hardware}}
   %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
     dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
     algorithm = #stablehlo.dot_algorithm<lhs_precision_type = f32, rhs_precision_type = i8, accumulation_type = f32, lhs_component_count = 1, rhs_component_count = 1, num_primitive_operations = 1, allow_imprecise_accumulation = false>
@@ -3354,7 +3354,7 @@
 // -----
 
 func.func @dot_general_i10(%arg0: tensor<2x2x2xi64>, %arg1: tensor<2x2x2xi64>) -> tensor<2x2x2xi64> {
-  // expected-error @+3 {{accumulation type must be float}}
+  // expected-error @+3 {{dot algorithm not known to be supported on any hardware}}
   %0 = "stablehlo.dot_general"(%arg0, %arg1) <{
     dot_dimension_numbers = #stablehlo.dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [0], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [1]>,
     algorithm = #stablehlo.dot_algorithm<lhs_precision_type = f32, rhs_precision_type = f32, accumulation_type = i8, lhs_component_count = 1, rhs_component_count = 1, num_primitive_operations = 1, allow_imprecise_accumulation = false>
diff --ruN a/stablehlo/stablehlo/tests/print_stablehlo.mlir b/stablehlo/stablehlo/tests/print_stablehlo.mlir
--- stablehlo/stablehlo/tests/print_stablehlo.mlir
+++ stablehlo/stablehlo/tests/print_stablehlo.mlir
@@ -315,8 +315,8 @@
   // CHECK-NEXT: {{%.*}} = stablehlo.dot_general %arg0, %arg1, batching_dims = [0] x [0], contracting_dims = [2] x [1], precision = [DEFAULT, DEFAULT] : (tensor<2x2x2xi8>, tensor<2x2x3xi8>) -> tensor<2x2x3xi32>
   // CHECK-NEXT: {{%.*}} = stablehlo.dot_general %arg2, %arg3, contracting_dims = [1] x [0] : (tensor<2x2xi8>, tensor<2x3xi8>) -> tensor<2x3xi32>
   // CHECK-NEXT: {{%.*}} = stablehlo.dot_general %arg2, %arg3, contracting_dims = [1] x [0], precision = [DEFAULT, DEFAULT] : (tensor<2x2xi8>, tensor<2x3xi8>) -> tensor<2x3xi32>
-  // CHECK-NEXT: {{%.*}} = stablehlo.dot_general %arg2, %arg3, contracting_dims = [1] x [0], precision = [DEFAULT, DEFAULT], algorithm = <lhs_precision_type = tf32, rhs_precision_type = tf32, accumulation_type = tf32, lhs_component_count = 1, rhs_component_count = 1, num_primitive_operations = 1, allow_imprecise_accumulation = false> : (tensor<2x2xi8>, tensor<2x3xi8>) -> tensor<2x3xi32>
-  // CHECK-NEXT: {{%.*}} = stablehlo.dot_general %arg2, %arg3, contracting_dims = [1] x [0], algorithm = <lhs_precision_type = tf32, rhs_precision_type = tf32, accumulation_type = tf32, lhs_component_count = 1, rhs_component_count = 1, num_primitive_operations = 1, allow_imprecise_accumulation = false> : (tensor<2x2xi8>, tensor<2x3xi8>) -> tensor<2x3xi32>
+  // CHECK-NEXT: {{%.*}} = stablehlo.dot_general %arg2, %arg3, contracting_dims = [1] x [0], precision = [DEFAULT, DEFAULT], algorithm = <lhs_precision_type = tf32, rhs_precision_type = tf32, accumulation_type = f32, lhs_component_count = 1, rhs_component_count = 1, num_primitive_operations = 1, allow_imprecise_accumulation = false> : (tensor<2x2xi8>, tensor<2x3xi8>) -> tensor<2x3xi32>
+  // CHECK-NEXT: {{%.*}} = stablehlo.dot_general %arg2, %arg3, contracting_dims = [1] x [0], algorithm = <lhs_precision_type = tf32, rhs_precision_type = tf32, accumulation_type = f32, lhs_component_count = 1, rhs_component_count = 1, num_primitive_operations = 1, allow_imprecise_accumulation = false> : (tensor<2x2xi8>, tensor<2x3xi8>) -> tensor<2x3xi32>
   %0 = "stablehlo.dot_general"(%arg0, %arg1) {
     dot_dimension_numbers = #stablehlo.dot<
       lhs_batching_dimensions = [0],
@@ -362,7 +362,7 @@
     algorithm = #stablehlo.dot_algorithm<
       lhs_precision_type = tf32,
       rhs_precision_type = tf32,
-      accumulation_type = tf32,
+      accumulation_type = f32,
       lhs_component_count = 1,
       rhs_component_count = 1,
       num_primitive_operations = 1,
@@ -379,7 +379,7 @@
     algorithm = #stablehlo.dot_algorithm<
       lhs_precision_type = tf32,
       rhs_precision_type = tf32,
-      accumulation_type = tf32,
+      accumulation_type = f32,
       lhs_component_count = 1,
       rhs_component_count = 1,
       num_primitive_operations = 1,

